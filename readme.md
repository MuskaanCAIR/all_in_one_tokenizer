# ALL-in-One Tokenizer and G2P Converter

This project constitues tokenization and g2p conversion tools for Indic, abjad and logographic writing scripts. Different tokenization tools were tested and after thorough research, the best tool among all for each of the following languages was chosen. Following is a table representing language name and their respective tokenization and g2p tool used in the project:

| Language | Tokenizer | G2P_tool |
--- | --- | --- | ---
Chinese | Jieba | G2pM |
Tibetan | Botok (Pybo) | THL
Shahmukhi | Spacy | Sangam (transliteraion)
Urdu | Spacy | Sangam (transliteration)
Bangla |
Sinhala | 

# Table of Content

1. Introduction to different tools:
    a. Tokenizers/ Word segmentation
    b. Grapheme - to - phoneme 
2. How to use the project
3. Brief description about code flow and project arrangement

